![Lamini](https://cdn.prod.website-files.com/65f9ebe58e6225ebad55ef60/6605f028392ea0cba018fbff_Open%20Graph%20Image.png)

# [Lamini](https://www.lamini.ai)

Lamini is an enterprise-focused AI platform that enables businesses to build and deploy custom large language models (LLMs) with high accuracy and minimal hallucinations. Their platform offers tools like Memory Tuning, which ensures precise factual recall, and guaranteed JSON output for seamless integration with existing applications. Lamini models can be run in various environments, including on-premises and public clouds, with support for both Nvidia and AMD GPUs. Their solutions cater to diverse industries, emphasizing data security and customization to meet specific business needs.

## Interface Name

- `lamini`


## Model Aliases

The following model aliases are provided for this provider. 

- `default`: meta-llama/Meta-Llama-3-8B-Instruct
- `large`: meta-llama/Meta-Llama-3-8B-Instruct
- `small`: microsoft/phi-2
- `agent`: meta-llama/Meta-Llama-3-8B-Instruct

## Embeddings

- `default`: sentence-transformers/all-MiniLM-L6-v2
- `large`: sentence-transformers/all-MiniLM-L6-v2
- `small`: sentence-transformers/all-MiniLM-L6-v2


## Options

The following values can be passed through `options`.

- `max_tokens`: The maximum number of tokens that can be generated in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length.
- `output_type`: _Details not available, please refer to Lamini documentation._


## Features

- Embeddings: true


## Lamini Documentation](undefined

[Lamini documentation](https://lamini-ai.github.io/about/) is available [here](https://lamini-ai.github.io/about/).
